{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9fc6205b",
   "metadata": {},
   "source": [
    "# Milvus Hybrid Search\n",
    "\n",
    ">[Milvus](https://milvus.io/docs/overview.md) is a database that stores, indexes, and manages massive embedding vectors generated by deep neural networks and other machine learning (ML) models.\n",
    "\n",
    "This notebook shows how to use functionality related to the Milvus>=2.4 vector database's [hybrid_search](https://milvus.io/api-reference/pymilvus/v2.4.x/ORM/Collection/hybrid_search.md). Beside `hybrid_search`, `MilvusHybridSearchRetriever` also supports normal single (dense or sparse) vector search, and Milvus's [scalar filtering query](https://milvus.io/docs/get-and-scalar-query.md). Note that you can also use langchain's [Milvus](https://python.langchain.com/docs/integrations/vectorstores/milvus/) vector store to do normal single vector search.\n",
    "\n",
    "To run, you should have a [Milvus instance up and running](https://milvus.io/docs/install_standalone-docker.md), Please make sure your Milvus instance version>=2.4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51489529-5dcd-4b86-bda6-de0a39d8ffd1",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1435c804-069d-4ade-9a7b-006b97b767c1",
   "metadata": {},
   "source": [
    "First, you need to install `pymilvus` python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a737220",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet pymilvus>=2.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c3d16",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e2ed9a",
   "metadata": {},
   "source": [
    "### Basic Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b0da28",
   "metadata": {},
   "source": [
    "Milvus vector database support both dense vector search and [sparse vector search](https://milvus.io/docs/sparse_vector.md). To use sparse vector search, we need a sparse embedding model, which embed text to sparse vector. Sparse vector is a high dimension vector, but almost all element is `0.0`. Let's first define a simple sparse embedding model, we will use a realworld [BGE-M3](https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/BGE_M3) sparse embedding model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0109a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "import random\n",
    "\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_community.retrievers.milvus_hybrid_search import SparseEmbeddings\n",
    "\n",
    "class FakeSparseEmbeddings(SparseEmbeddings):\n",
    "    def embed_documents(self, texts: List[str]) -> List[Dict[int, float]]:\n",
    "        random.seed(0)\n",
    "        n = 100  # sparse vector's dimension\n",
    "        sparse_vectors = []\n",
    "        for text in texts:\n",
    "            vector_dict = {}\n",
    "            k = random.randint(0, 4)\n",
    "            for i in range(k):\n",
    "                vector_dict[random.randint(0, n)] = random.random()\n",
    "            # Hack: This maybe Milvus's bug, which cannot accept an all zero sparse vector.\n",
    "            if not vector_dict:\n",
    "                vector_dict = {0: 0.000001}\n",
    "            sparse_vectors.append(vector_dict)\n",
    "        return sparse_vectors\n",
    "\n",
    "    def embed_query(self, text: str) -> List[Dict[int, float]]:\n",
    "        return self.embed_documents([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef059b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_embeddings = FakeSparseEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dc04986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{53: 0.7579544029403025, 65: 0.04048437818077755, 100: 0.48592769656281265},\n",
       " {45: 0.9677999949201714, 27: 0.5833820394550312}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_embeddings.embed_documents([\"text-a\", \"text-b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95523571",
   "metadata": {},
   "source": [
    "To use hybrid search, we need one more embedding model, so we define a normal dense embedding as following.\n",
    "\n",
    "Note: to use hybrid search, you can use more than two embedding models, no matter they are sparse or dense embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ccb9445",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeDenseEmbeddings(Embeddings):\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        random.seed(42)\n",
    "        return [[random.random() for i in range(3)] for text in texts]\n",
    "    \n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.embed_documents([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1169bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_embeddings = FakeDenseEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3860365b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6394267984578837, 0.025010755222666936, 0.27502931836911926],\n",
       " [0.22321073814882275, 0.7364712141640124, 0.6766994874229113]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_embeddings.embed_documents([\"text-a\", \"text-b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2473e5",
   "metadata": {},
   "source": [
    "Now, we can use hybrid search by using `MilvusHybridSearchRetriever`, the process of hybrid search under the hood is independent perform vector search for each embedding model, then a rerank model will combine these results to the final result. At the writing time, milvus support RRF (Reciprocal Rank Fusion) and Weighted rerank model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "170bf8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers.milvus_hybrid_search import MilvusHybridSearchRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef94739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = MilvusHybridSearchRetriever(\n",
    "    embedding_functions={\n",
    "        \"dense\": FakeDenseEmbeddings()\n",
    "    },\n",
    "    sparse_embedding_functions={\n",
    "        \"sparse\": FakeSparseEmbeddings()\n",
    "    },\n",
    "    drop_old=True,  # drop the aleady exist collection named \"LangChainCollection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f2c180f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_a', 'id_b', 'id_c', 'id_d', 'id_e']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.add_texts(\n",
    "    [\"a\", \"b\", \"c\", \"d\", \"e\"],\n",
    "    ids=[\"id_a\", \"id_b\", \"id_c\", \"id_d\", \"id_e\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38c687ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(input=\"d\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0330b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='d'),\n",
       " Document(page_content='c'),\n",
       " Document(page_content='a')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e73100",
   "metadata": {},
   "source": [
    "To inspect the detail of search and rerank params, you can use the debug mode like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0c9cb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from langchain_community.retrievers.milvus_hybrid_search import logger\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = logging.StreamHandler()\n",
    "handler.setLevel(logging.DEBUG)\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f87549b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vector search reqs:\n",
      "anns_field: dense, param: {'param': {'metric_type': 'L2', 'params': {'ef': 10}}}, limit: 3, expr: None\n",
      "anns_field: sparse, param: {'param': {'metric_type': 'IP', 'params': {'drop_ratio_search': 0.0}}}, limit: 3, expr: None\n",
      "rerank: {'strategy': 'rrf', 'params': {'k': 60.0}}\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.invoke(input=\"d\", k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a269023",
   "metadata": {},
   "source": [
    "### Try different index and search type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76355489",
   "metadata": {},
   "source": [
    "Milvus provides several [index types](https://milvus.io/docs/index.md) for vector fields, but be careful that `search_params` should be compatible with `index_params`. When using `MilvusHybridSearchRetriever`, you can try different index types via `index_params`, the corresponding compatible and default `search_params` is likely out of box. Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14dcc249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using previous connection: f04753763e6b4fcb8dc783d1af7763aa\n"
     ]
    }
   ],
   "source": [
    "retriever = MilvusHybridSearchRetriever(\n",
    "    embedding_functions={\n",
    "        \"dense\": FakeDenseEmbeddings()\n",
    "    },\n",
    "    sparse_embedding_functions={\n",
    "        \"sparse\": FakeSparseEmbeddings()\n",
    "    },\n",
    "    drop_old=True,  # drop the aleady exist collection named \"LangChainCollection\",\n",
    "    index_params={\n",
    "        \"dense\": {\n",
    "            \"metric_type\": \"COSINE\",\n",
    "            \"index_type\": \"IVF_FLAT\",\n",
    "            \"params\": {\"nlist\": 32}\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8d90d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully created an index on collection: LangChainCollection, field_name: dense\n",
      "Successfully created an index on collection: LangChainCollection, field_name: sparse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['id_a', 'id_b', 'id_c', 'id_d', 'id_e']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.add_texts(\n",
    "    [\"a\", \"b\", \"c\", \"d\", \"e\"],\n",
    "    ids=[\"id_a\", \"id_b\", \"id_c\", \"id_d\", \"id_e\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "881ce1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dense': {'param': {'metric_type': 'COSINE', 'params': {'nprobe': 10}}},\n",
       " 'sparse': {'param': {'metric_type': 'IP',\n",
       "   'params': {'drop_ratio_search': 0.0}}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.search_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171292df",
   "metadata": {},
   "source": [
    "You can also manually specific a compatible `search_params` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a607a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using previous connection: f04753763e6b4fcb8dc783d1af7763aa\n"
     ]
    }
   ],
   "source": [
    "retriever = MilvusHybridSearchRetriever(\n",
    "    embedding_functions={\n",
    "        \"dense\": FakeDenseEmbeddings()\n",
    "    },\n",
    "    sparse_embedding_functions={\n",
    "        \"sparse\": FakeSparseEmbeddings()\n",
    "    },\n",
    "    drop_old=True,  # drop the aleady exist collection named \"LangChainCollection\",\n",
    "    index_params={\n",
    "        \"dense\": {\n",
    "            \"metric_type\": \"COSINE\",\n",
    "            \"index_type\": \"IVF_FLAT\",\n",
    "            \"params\": {\"nlist\": 32}\n",
    "        }\n",
    "    },\n",
    "    search_params={\n",
    "        \"dense\": {\n",
    "            \"metric_type\": \"COSINE\",\n",
    "            \"params\": {\"nprobe\": 5},\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffb94b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully created an index on collection: LangChainCollection, field_name: dense\n",
      "Successfully created an index on collection: LangChainCollection, field_name: sparse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['id_a', 'id_b', 'id_c', 'id_d', 'id_e']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.add_texts(\n",
    "    [\"a\", \"b\", \"c\", \"d\", \"e\"],\n",
    "    ids=[\"id_a\", \"id_b\", \"id_c\", \"id_d\", \"id_e\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c20546",
   "metadata": {},
   "source": [
    "Lastly, you can also manually specific a compatible `ann_search_params` for this single search process like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44b16c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vector search reqs:\n",
      "anns_field: dense, param: {'metric_type': 'COSINE', 'params': {'nprobe': 3}}, limit: 2, expr: None\n",
      "anns_field: sparse, param: {'param': {'metric_type': 'IP', 'params': {'drop_ratio_search': 0.0}}}, limit: 4, expr: None\n",
      "rerank: {'strategy': 'rrf', 'params': {'k': 60.0}}\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.invoke(\n",
    "    \"d\",\n",
    "    k=3,\n",
    "    ann_search_params={\n",
    "        \"dense\": {\n",
    "            \"param\": {\"metric_type\": \"COSINE\", \"params\": {\"nprobe\": 3}},  # should be compatible with index params\n",
    "            \"limit\": 2,\n",
    "        },\n",
    "        \"sparse\": {\n",
    "            \"limit\": 4,\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b253dd0",
   "metadata": {},
   "source": [
    "### Using subset of vector fields to retrieve"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0570b51d",
   "metadata": {},
   "source": [
    "#### single vector search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0216fd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using single vector search on dense\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.invoke(\n",
    "    \"d\",\n",
    "    k=2,\n",
    "    ann_search_params={\"dense\": {}},\n",
    "    include_other_fields=False  # important: avoid to involve other vector fields not present in ann_search_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3018a5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='a'), Document(page_content='c')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19742e8",
   "metadata": {},
   "source": [
    "#### scalar filtering query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "688ec39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using query, expr=pk in ['id_a', 'id_b', 'id_c']\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.invoke(\n",
    "    \"d\",\n",
    "    k=2,\n",
    "    include_other_fields=False,\n",
    "    expr=\"pk in ['id_a', 'id_b', 'id_c']\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db7a46d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='a'), Document(page_content='b')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45708671",
   "metadata": {},
   "source": [
    "### A realworld example: BGE-M3 dense and sparse hybrid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321c267d",
   "metadata": {},
   "source": [
    "This section will show you how to use BGE-M3 hybrid search via `MilvusHybridSearchRetriever` like this [example](https://github.com/milvus-io/pymilvus/blob/master/examples/hello_hybrid_sparse_dense.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75474bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install FlagEmbedding --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3480e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61d29207",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BGEM3SparseEmbeddings(SparseEmbeddings):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def embed_documents(self, texts: List[str]) -> List[Dict[int, float]]:\n",
    "        weights = self.model.encode(\n",
    "            texts,\n",
    "            batch_size=4,\n",
    "            max_length=8192,\n",
    "            return_dense=False,\n",
    "            return_sparse=True\n",
    "        )['lexical_weights']\n",
    "        sparse_vectors = [\n",
    "            {int(k): float(v) for k, v in weight_dict.items()}\n",
    "            for weight_dict in weights\n",
    "        ]\n",
    "        return sparse_vectors\n",
    "    \n",
    "    def embed_query(self, text: str) -> Dict[int, float]:\n",
    "        return self.embed_documents([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf411499",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BGEM3DenseEmbeddings(Embeddings):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        dense_vectors = self.model.encode(\n",
    "            texts,\n",
    "            batch_size=4,\n",
    "            max_length=8192,\n",
    "            return_dense=True,\n",
    "        )['dense_vecs'].tolist()\n",
    "        return dense_vectors\n",
    "    \n",
    "    def embed_query(self, text: str) -> Dict[int, float]:\n",
    "        return self.embed_documents([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3dc153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"foo\", \"bar\", \"food\", \"bare\", \"hi\", \"hello\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b12b5cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using previous connection: f04753763e6b4fcb8dc783d1af7763aa\n"
     ]
    }
   ],
   "source": [
    "retriever = MilvusHybridSearchRetriever(\n",
    "    embedding_functions={\n",
    "        \"dense\": BGEM3DenseEmbeddings(model)\n",
    "    },\n",
    "    sparse_embedding_functions={\n",
    "        \"sparse\": BGEM3SparseEmbeddings(model)\n",
    "    },\n",
    "    drop_old=True,\n",
    "    auto_id=True,  # if set `auto_id=True`, then you don't need pass `ids` to `add_texts`\n",
    "    rerank_params={\"type\": \"Weighted\", \"param\": {\"weights\": {\"dense\": 0.7, \"sparse\": 0.3}}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc30c0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully created an index on collection: LangChainCollection, field_name: dense\n",
      "Successfully created an index on collection: LangChainCollection, field_name: sparse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[449456496514633207,\n",
       " 449456496514633208,\n",
       " 449456496514633209,\n",
       " 449456496514633210,\n",
       " 449456496514633211,\n",
       " 449456496514633212]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.add_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "918eb555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vector search reqs:\n",
      "anns_field: dense, param: {'param': {'metric_type': 'L2', 'params': {'ef': 10}}}, limit: 3, expr: None\n",
      "anns_field: sparse, param: {'param': {'metric_type': 'IP', 'params': {'drop_ratio_search': 0.0}}}, limit: 3, expr: None\n",
      "rerank: {'strategy': 'weighted', 'params': {'weights': [0.7, 0.3]}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='food'),\n",
       " Document(page_content='hi'),\n",
       " Document(page_content='hello')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\n",
    "    \"fruit\",\n",
    "    k=3,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
